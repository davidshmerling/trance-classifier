import json
import numpy as np
import tensorflow as tf

# ğŸ“Œ ×™×™×‘×•× *×¨×§* ×©×œ ×¤×¨××˜×¨×™× ×©× ××¦××™× ×‘×§×•× ×¤×™×’
from config import (
    DATA_DIR,
    CACHE_DIR,
    VALID_GENRES,
    EMB_SHAPE,
    META_VECTOR_LENGTH,
    NUM_GENRES
)

# ×™×¦×™×¨×ª cache ×× ×œ× ×§×™×™×
CACHE_DIR.mkdir(parents=True, exist_ok=True)


# ============================================================
# ğŸ§± ×™×¦×™×¨×ª Cache ××”Ö¾data ×”×—×“×©
# ============================================================
def build_cache():
    emb_list, meta_list, labels = [], [], []

    for genre in VALID_GENRES:
        genre_path = DATA_DIR / genre
        if not genre_path.exists():
            print(f"âš ï¸ {genre_path} ×œ× ×§×™×™××ª â€” ××“×œ×’.")
            continue

        print(f"ğŸ“ ×¡×•×¨×§: {genre}")

        # ×—×™×¤×•×© ×§×‘×¦×™ embedding ×‘×œ×‘×“
        for emb_path in genre_path.rglob("part_*.npy"):
            if "_meta.npy" in str(emb_path):
                continue  # ××“×œ×’ ×¢×œ ×§×‘×¦×™ ××˜×

            stem = emb_path.stem.replace("part_", "")
            meta_path = emb_path.parent / f"part_{stem}_meta.npy"

            if not emb_path.exists() or not meta_path.exists():
                print(f"âš ï¸ ×—×¡×¨×™× ×§×‘×¦×™× ×¢×‘×•×¨ {emb_path.parent} â€” ××“×œ×’.")
                continue

            # ×˜×¢×™× ×ª embedding
            emb = np.load(emb_path).astype(np.float32)
            if emb.shape != EMB_SHAPE:
                raise ValueError(
                    f"âŒ ×¦×•×¨×ª embedding ×©×’×•×™×” ({emb.shape}) â€” ×‘×§×•×‘×¥ ×¦×™×¤×™× ×• {EMB_SHAPE}"
                )

            # ×˜×¢×™× ×ª meta
            meta = np.load(meta_path).astype(np.float32)
            if meta.shape != (META_VECTOR_LENGTH,):
                raise ValueError(
                    f"âŒ meta ×©×’×•×™ ({meta.shape}) â€” ×‘×§×•× ×¤×™×’ ×¦×™×¤×™× ×• {META_VECTOR_LENGTH}"
                )

            emb_list.append(emb)
            meta_list.append(meta)
            labels.append(genre)

    # ×¡×™×›×•×
    n = len(emb_list)
    print(f"\nâœ” × ×˜×¢× ×• {n} ×“×’×™××•×ª")

    if n == 0:
        raise RuntimeError("âŒ ××™×Ÿ ×“××˜×” â€” ×‘×“×•×§ ××ª ×ª×™×§×™×™×ª data/")

    X_emb = np.array(emb_list, dtype=np.float32)
    X_meta = np.array(meta_list, dtype=np.float32)

    # ×”××¨×ª ×œ-one-hot
    genre_to_idx = {g: i for i, g in enumerate(VALID_GENRES)}
    y_idx = np.array([genre_to_idx[g] for g in labels], dtype=np.int32)
    y = tf.keras.utils.to_categorical(y_idx, NUM_GENRES)

    # ×©××™×¨×” ×œ×§××©
    np.save(CACHE_DIR / "X_emb.npy", X_emb)
    np.save(CACHE_DIR / "X_meta.npy", X_meta)
    np.save(CACHE_DIR / "y.npy", y)

    meta_info = dict(
        genres=VALID_GENRES,
        num_samples=n,
        emb_shape=EMB_SHAPE,
        meta_shape=(META_VECTOR_LENGTH,),
        author="ğŸš€ Trance Classifier Automation"
    )
    json.dump(meta_info, open(CACHE_DIR / "meta.json", "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    print("ğŸ“¦ cache × ×•×¦×¨ ×‘×”×¦×œ×—×”!")


# ============================================================
# ğŸ“¥ ×˜×¢×™× ×ª ×”×“××˜×” ××”-cache
# ============================================================
def load_dataset(val_split=0.2):
    paths = {
        "emb": CACHE_DIR / "X_emb.npy",
        "meta": CACHE_DIR / "X_meta.npy",
        "y": CACHE_DIR / "y.npy",
    }

    missing = [str(p) for p in paths.values() if not p.exists()]
    if missing:
        raise FileNotFoundError(
            "âŒ ×§×‘×¦×™ cache ×—×¡×¨×™×. ×”×¨×¥ build_cache().\n" + "\n".join(missing)
        )

    X_emb = np.load(paths["emb"])
    X_meta = np.load(paths["meta"])
    y = np.load(paths["y"])

    N = len(X_emb)
    print(f"âœ” × ×˜×¢×Ÿ cache: {N} ×“×’×™××•×ª")

    y_idx_full = np.argmax(y, axis=1)

    # ×¢×¨×‘×•×‘
    perm = np.random.permutation(N)
    X_emb, X_meta, y, y_idx_full = \
        X_emb[perm], X_meta[perm], y[perm], y_idx_full[perm]

    val_size = int(N * val_split)

    # ×—×œ×•×§×”
    X_emb_val = X_emb[:val_size]
    X_meta_val = X_meta[:val_size]
    y_val = y[:val_size]

    X_emb_train = X_emb[val_size:]
    X_meta_train = X_meta[val_size:]
    y_train = y[val_size:]
    y_train_idx = y_idx_full[val_size:]

    print(f"ğŸ“Š Train: {len(X_emb_train)} | Val: {len(X_emb_val)}")

    return (
        X_emb_train, X_meta_train, y_train, y_train_idx,
        X_emb_val, X_meta_val, y_val
    )


# ============================================
# â–¶ MAIN
# ============================================
if __name__ == "__main__":
    build_cache()
