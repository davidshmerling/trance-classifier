import os
import time
import numpy as np
import tensorflow as tf
from PIL import Image
from pathlib import Path
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils.class_weight import compute_class_weight

# ============================================
# âš™ï¸ ×—×œ×§ 0 â€” ×§×•× ×¤×™×’×•×¨×¦×™×” ×‘×¡×™×¡×™×ª ×•×–×¨×¢×™×
# ============================================

layers = tf.keras.layers
models = tf.keras.models

DATA_DIR = "data"
MODELS_DIR = "models"
LATEST_MODEL = os.path.join(MODELS_DIR, "latest.h5")

IMG_SIZE = (299, 299)
BATCH_SIZE = 16
EPOCHS = 20

VALID_GENRES = ["goa", "psy", "dark"]

# ×–×¨×¢×™× ×œ×©×—×–×•×¨×™×•×ª ×‘×¡×™×¡×™×ª
np.random.seed(42)
tf.random.set_seed(42)

sns.set(style="whitegrid")


# ============================================
# ğŸ“¥ ×—×œ×§ 1 â€” ×˜×¢×™× ×ª ×”×“××˜×” ××”×“×™×¡×§ ×œ×–×™×›×¨×•×Ÿ
# ============================================
# ×˜×•×¢×Ÿ ×ª××•× ×•×ª (×¡×¤×§×˜×•×’×¨××•×ª) ×•Ö¾embeddings (10Ã—68) ×œ×›×œ ×§×˜×¢
# ××—×–×™×¨ ×¡×˜ ××™××•×Ÿ ×•×¡×˜ ×•×œ×™×“×¦×™×” (80/20) + ×ª×•×•×™×•×ª one-hot + ××™× ×“×§×¡×™× ×œ××—×œ×§×•×ª


def load_dataset():
    img_list = []
    emb_list = []
    labels = []

    for genre in VALID_GENRES:
        genre_path = Path(DATA_DIR) / genre
        if not genre_path.exists():
            continue

        for root, dirs, files in os.walk(genre_path):
            for f in files:
                if not f.endswith(".png"):
                    continue

                img_path = os.path.join(root, f)
                emb_path = img_path.replace(".png", ".npy")
                if not os.path.exists(emb_path):
                    continue

                # ---- ×ª××•× ×” ----
                img = Image.open(img_path).convert("RGB").resize(IMG_SIZE)
                img = np.array(img, dtype=np.float32) / 255.0  # [0,1]

                # ---- ×××‘×“×™× ×’ (10Ã—68) ----
                emb = np.load(emb_path).astype(np.float32)  # shape: (10, 68)

                # ×‘×“×™×§×” ×§×©×™×—×” ×©×”×¦×•×¨×” × ×›×•× ×”
                if emb.shape != (10, 68):
                    print(f"âš ï¸ ××–×”×¨×”: embedding ×‘× ×ª×™×‘ {emb_path} ×”×•× ×‘×¦×•×¨×” {emb.shape}, ××“×œ×’.")
                    continue

                img_list.append(img)
                emb_list.append(emb)
                labels.append(genre)

    print(f"âœ” Loaded {len(img_list)} samples")

    if len(img_list) == 0:
        raise RuntimeError("×œ× × ×˜×¢× ×• ×“×’×™××•×ª. ×‘×“×•×§ ×©×”×¡×¤×¨×™×™×” data/ ×§×™×™××ª ×•×™×© ×‘×” ×§×‘×¦×™×.")

    # ×”××¨×” ×œÖ¾numpy
    X_img = np.array(img_list, dtype=np.float32)          # (N, 299, 299, 3)
    X_emb = np.array(emb_list, dtype=np.float32)          # (N, 10, 68)

    # ×”××¨×ª ×ª×’×™×•×ª ×œ××™× ×“×§×¡×™× ×•Ö¾one-hot
    genre_to_idx = {g: i for i, g in enumerate(VALID_GENRES)}
    y_idx = np.array([genre_to_idx[g] for g in labels], dtype=np.int32)
    y = tf.keras.utils.to_categorical(y_idx, num_classes=len(VALID_GENRES))

    # ×¢×¨×‘×•×‘
    idx = np.arange(len(X_img))
    np.random.shuffle(idx)
    X_img = X_img[idx]
    X_emb = X_emb[idx]
    y = y[idx]
    y_idx = y_idx[idx]

    # ×—×œ×•×§×” 80/20 (×•×œ×™×“×¦×™×” ××”×”×ª×—×œ×” ×©×œ ×”××¢×¨×š ××—×¨×™ ×¢×¨×‘×•×‘)
    val_size = int(0.2 * len(X_img))

    X_img_val = X_img[:val_size]
    X_emb_val = X_emb[:val_size]
    y_val = y[:val_size]

    X_img_train = X_img[val_size:]
    X_emb_train = X_emb[val_size:]
    y_train = y[val_size:]
    y_train_idx = y_idx[val_size:]

    print(f"Train samples = {len(X_img_train)}  |  Val = {len(X_img_val)}")

    return (
        X_img_train, X_emb_train, y_train, y_train_idx,
        X_img_val, X_emb_val, y_val
    )


# ============================================
# ğŸ§  ×—×œ×§ 2 â€” ×‘× ×™×™×ª ×”××•×“×œ (EfficientNetB0 + GRU)
# ============================================
# ××•×“×œ ×“×•-×¢× ×¤×™:
# 1. ×¢× ×£ ×ª××•× ×”: EfficientNetB0 (××•×§×¤× ×‘×ª×—×™×œ×”) + GAP + Dense
# 2. ×¢× ×£ ×××‘×“×™× ×’: GRU ×“×•-×©×œ×‘×™ ×¢×œ ×¨×¦×£ ×©×œ 10Ã—68
# ×œ××—×¨ ××›×Ÿ ×××—×“×™× (Concatenate) ×•××•×¡×™×¤×™× ×©×›×‘×•×ª Fully Connected


def build_model(num_classes):

    # ------------------
    # ×¢× ×£ ×ª××•× ×” â€” EfficientNetB0
    # ------------------
    base = tf.keras.applications.EfficientNetB0(
        include_top=False,
        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),
        weights="imagenet"
    )

    base.trainable = False  # ×‘×©×œ×‘ ×¨××©×•×Ÿ ××§×¤×™××™×. ××¤×©×¨ ×œ×¤×ª×•×— ×‘×¡×•×£ ×”××™××•×Ÿ ×œ×¤×™×™×Ÿ-×˜×™×•× ×™× ×’.

    img_input = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), name="image_input")

    # ××¤×©×¨ ×œ×”×•×¡×™×£ ××•×’×× ×˜×¦×™×” ×§×œ×” (×œ× ×—×•×‘×”)
    aug = layers.RandomFlip("horizontal")(img_input)
    aug = layers.RandomRotation(0.05)(aug)

    x = base(aug, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.3)(x)
    img_vec = layers.Dense(128, activation="relu", name="img_dense")(x)

    # ------------------
    # ×¢× ×£ ×××‘×“×™× ×’ â€” GRU ×¢×œ ×¨×¦×£ 10Ã—68
    # ------------------
    emb_input = layers.Input(shape=(10, 68), name="embedding_input")

    e = layers.GRU(128, return_sequences=True, name="emb_gru_1")(emb_input)
    e = layers.GRU(64, return_sequences=False, name="emb_gru_2")(e)
    e = layers.Dropout(0.3)(e)
    emb_vec = layers.Dense(64, activation="relu", name="emb_dense")(e)

    # ------------------
    # ××™×—×•×“ ×•×¨××© ×¡×™×•×•×’
    # ------------------
    combined = layers.Concatenate(name="concat")([img_vec, emb_vec])

    x = layers.Dense(128, activation="relu")(combined)
    x = layers.Dropout(0.4)(x)
    x = layers.Dense(64, activation="relu")(x)
    out = layers.Dense(num_classes, activation="softmax", name="output")(x)

    model = models.Model(inputs=[img_input, emb_input], outputs=out, name="TranceCRNN_EfficientNet")

    model.compile(
        optimizer=tf.keras.optimizers.Adam(1e-4),
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )

    model.summary()
    return model


# ============================================
# ğŸ’¾ ×—×œ×§ 3 â€” ×©××™×¨×ª ×”××•×“×œ ×‘×’×¨×¡××•×ª
# ============================================
# ×©×•××¨ ××•×“×œ ×‘×ª×™×§×™×™×” ×—×“×©×” models/vX/model.h5
# ×•×’× ×¢×•×©×” copy ×œÖ¾models/latest.h5 ×œ×¦×•×¨×š ×©×™××•×© ×‘××¤×œ×™×§×¦×™×”


def save_versioned_model(model):
    os.makedirs(MODELS_DIR, exist_ok=True)

    versions = [
        int(f.name.replace("v", ""))
        for f in Path(MODELS_DIR).glob("v*")
        if f.is_dir() and f.name.replace("v", "").isdigit()
    ]
    next_v = (max(versions) + 1) if versions else 1

    version_dir = Path(MODELS_DIR) / f"v{next_v}"
    version_dir.mkdir(parents=True, exist_ok=True)

    model_path = version_dir / "model.h5"
    model.save(model_path)

    # ×¢×“×›×•×Ÿ latest.h5
    shutil.copy(model_path, LATEST_MODEL)

    print(f"âœ” Saved model to {model_path}")
    print(f"âœ” Updated latest model at {LATEST_MODEL}")

    return version_dir


# ============================================
# ğŸ“Š ×—×œ×§ 4 â€” × ×™×ª×•×— ×ª×•×¦××•×ª (Confusion Matrix + Report + ×’×¨×¤×™×)
# ============================================
# ××™×™×¦×¨:
# - ××˜×¨×™×¦×ª ×‘×œ×‘×•×œ (confusion_matrix.png)
# - ×“×•×— ×˜×§×¡×˜×•××œ×™ (report.txt)
# - ×’×¨×£ ×“×™×•×§ (accuracy.png)
# - ×’×¨×£ ×”×¤×¡×“ (loss.png)


def analyze_results(model, history, X_img_val, X_emb_val, y_val, version_dir):
    analysis_dir = version_dir / "analysis"
    analysis_dir.mkdir(parents=True, exist_ok=True)

    # ×—×™×–×•×™ ×¢×œ ×¡×˜ ×”×•×œ×™×“×¦×™×”
    y_true = np.argmax(y_val, axis=1)
    y_pred = np.argmax(model.predict([X_img_val, X_emb_val]), axis=1)

    # ××˜×¨×™×¦×ª ×‘×œ×‘×•×œ
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d",
                xticklabels=VALID_GENRES,
                yticklabels=VALID_GENRES,
                cmap="Blues")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix")
    plt.tight_layout()
    plt.savefig(analysis_dir / "confusion_matrix.png")
    plt.close()

    # ×“×•×— ×˜×§×¡×˜×•××œ×™
    report = classification_report(
        y_true, y_pred, target_names=VALID_GENRES, digits=3
    )
    with open(analysis_dir / "report.txt", "w", encoding="utf-8") as f:
        f.write(report)

    # ×’×¨×£ ×“×™×•×§
    plt.figure()
    plt.plot(history.history["accuracy"], label="Train Accuracy")
    plt.plot(history.history["val_accuracy"], label="Val Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(analysis_dir / "accuracy.png")
    plt.close()

    # ×’×¨×£ ×”×¤×¡×“
    plt.figure()
    plt.plot(history.history["loss"], label="Train Loss")
    plt.plot(history.history["val_loss"], label="Val Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(analysis_dir / "loss.png")
    plt.close()

    print(f"âœ” Analysis saved under: {analysis_dir}")


# ============================================
# ğŸƒâ€â™‚ï¸ ×—×œ×§ 5 â€” ×œ×•×œ××ª ×”××™××•×Ÿ ×”×¨××©×™×ª
# ============================================
# ×˜×•×¢×Ÿ ×“××˜×”, ××—×©×‘ class_weights, ××××Ÿ ××ª ×”××•×“×œ ×¢× callbacks,
# ×©×•××¨ ×’×¨×¡×” ×•××¨×™×¥ ×× ×œ×™×–×” ×¢×œ ×¡×˜ ×”×•×œ×™×“×¦×™×”


def train_model():
    print("============== Training ==============")

    (
        X_img_train, X_emb_train, y_train, y_train_idx,
        X_img_val, X_emb_val, y_val
    ) = load_dataset()

    # ×—×™×©×•×‘ ××©×§×œ×™ ××—×œ×§×•×ª ×œ×˜×™×¤×•×œ ×‘×—×•×¡×¨ ××™×–×•×Ÿ
    cw = compute_class_weight(
        class_weight='balanced',
        classes=np.unique(y_train_idx),
        y=y_train_idx
    )
    class_weights = {i: float(w) for i, w in enumerate(cw)}
    print("Class weights:", class_weights)

    model = build_model(num_classes=len(VALID_GENRES))

    # Callbacks â€” ×¢×¦×™×¨×ª early stopping + ×©×™× ×•×™ lr ×›×©×”×•×œ×™×“×¦×™×” × ×ª×§×¢×ª
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            patience=4,
            restore_best_weights=True,
            monitor="val_loss"
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="val_loss",
            factor=0.5,
            patience=2,
            verbose=1,
            min_lr=1e-6
        )
    ]

    start_time = time.time()

    history = model.fit(
        [X_img_train, X_emb_train], y_train,
        validation_data=([X_img_val, X_emb_val], y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        class_weight=class_weights,
        callbacks=callbacks,
        verbose=1,
    )

    total_time = time.time() - start_time
    print(f"\nâ± Training time: {total_time:.2f} seconds")

    # ×©××™×¨×ª ××•×“×œ ×‘×’×¨×¡×ª vX + latest.h5
    version_dir = save_versioned_model(model)

    # × ×™×ª×•×— ×ª×•×¦××•×ª ×•×©××™×¨×ª ×’×¨×¤×™×
    analyze_results(model, history, X_img_val, X_emb_val, y_val, version_dir)

    print("\nâœ” DONE\n")


# ============================================
# ğŸ”š ×—×œ×§ 6 â€” × ×§×•×“×ª ×›× ×™×¡×” ×œ×§×•×‘×¥
# ============================================
if __name__ == "__main__":
    train_model()
