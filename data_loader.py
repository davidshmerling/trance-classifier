import json
from pathlib import Path
import numpy as np
from PIL import Image
import tensorflow as tf

# ============================================
# âš™ï¸ ×§×•× ×¤×™×’×•×¨×¦×™×”
# ============================================

DATA_DIR = Path("data")
CACHE_DIR = Path("data_cache")

IMG_SIZE = (299, 299)
VALID_GENRES = ["goa", "psy", "dark"]

CACHE_DIR.mkdir(exist_ok=True)


# ============================================
# ğŸ§± ×‘× ×™×™×ª CACHE ××”×§×‘×¦×™× ×”×’×•×œ××™×™×
# ============================================

def build_cache():
    img_list, emb_list, labels = [], [], []

    for genre in VALID_GENRES:
        genre_path = DATA_DIR / genre
        if not genre_path.exists():
            print(f"âš ï¸ {genre_path} ×œ× ×§×™×™××ª â€” ××“×œ×’.")
            continue

        print(f"ğŸ“ ×¡×•×¨×§: {genre}")

        for png_path in genre_path.rglob("*.png"):
            npy_path = png_path.with_suffix(".npy")
            if not npy_path.exists():
                print(f"âš ï¸ ×—×¡×¨ embedding ×¢×‘×•×¨ {png_path} â€” ××“×œ×’.")
                continue

            # ×ª××•× ×”
            img = Image.open(png_path).convert("RGB").resize(IMG_SIZE)
            img = np.asarray(img, dtype=np.float32) / 255.0

            # ×××‘×“×™× ×’
            emb = np.load(npy_path).astype(np.float32)
            if emb.shape != (10, 68):
                print(f"âš ï¸ embedding ×¤×’×•×: {npy_path} â€” ××“×œ×’.")
                continue

            img_list.append(img)
            emb_list.append(emb)
            labels.append(genre)

    n = len(img_list)
    print(f"\nâœ” × ×˜×¢× ×• {n} ×“×’×™××•×ª")

    if n == 0:
        raise RuntimeError("âŒ ××™×Ÿ ×“××˜×” â€” ×‘×“×•×§ ××ª ×ª×™×§×™×™×ª data/.")

    # ×”××¨×•×ª
    X_img = np.array(img_list, dtype=np.float32)
    X_emb = np.array(emb_list, dtype=np.float32)

    genre_to_idx = {g: i for i, g in enumerate(VALID_GENRES)}
    y_idx = np.array([genre_to_idx[g] for g in labels], dtype=np.int32)
    y = tf.keras.utils.to_categorical(y_idx, len(VALID_GENRES))

    # ×©××™×¨×”
    np.save(CACHE_DIR / "X_img.npy", X_img)
    np.save(CACHE_DIR / "X_emb.npy", X_emb)
    np.save(CACHE_DIR / "y.npy", y)

    meta = dict(
        genres=VALID_GENRES,
        num_samples=n,
        img_size=IMG_SIZE,
        emb_shape=(10, 68),
    )
    json.dump(meta, open(CACHE_DIR / "meta.json", "w", encoding="utf-8"), indent=2, ensure_ascii=False)

    print("ğŸ“¦ cache × ×•×¦×¨ ×‘×”×¦×œ×—×”!")


# ============================================
# ğŸ“¥ ×˜×¢×™× ×ª ×”×“××˜×” ××”-cache
# ============================================

def load_dataset(val_split=0.2):
    """×˜×•×¢×Ÿ ××ª ×”Ö¾cache ×”××•×›×Ÿ, ××¢×¨×‘×‘ ×•××—×œ×§ ×œÖ¾train/val."""

    # × ×ª×™×‘×™× ×¦×¤×•×™×™×
    paths = {
        "img": CACHE_DIR / "X_img.npy",
        "emb": CACHE_DIR / "X_emb.npy",
        "y": CACHE_DIR / "y.npy",
    }

    # ×‘×“×™×§×ª ×§×™×•×
    missing = [str(p) for p in paths.values() if not p.exists()]
    if missing:
        raise FileNotFoundError(
            "âŒ ×§×‘×¦×™ cache ×—×¡×¨×™×. ×”×¨×¥ build_cache().\n" + "\n".join(missing)
        )

    # ×˜×¢×™× ×”
    X_img = np.load(paths["img"])
    X_emb = np.load(paths["emb"])
    y = np.load(paths["y"])

    N = len(X_img)
    print(f"âœ” × ×˜×¢×Ÿ cache: {N} ×“×’×™××•×ª")

    y_idx_full = np.argmax(y, axis=1)

    # ×¢×¨×‘×•×‘
    perm = np.random.permutation(N)
    X_img, X_emb, y, y_idx_full = X_img[perm], X_emb[perm], y[perm], y_idx_full[perm]

    # ×—×œ×•×§×”
    val_size = int(N * val_split)

    X_img_val = X_img[:val_size]
    X_emb_val = X_emb[:val_size]
    y_val = y[:val_size]

    X_img_train = X_img[val_size:]
    X_emb_train = X_emb[val_size:]
    y_train = y[val_size:]
    y_train_idx = y_idx_full[val_size:]

    print(f"Train: {len(X_img_train)} | Val: {len(X_img_val)}")

    return (
        X_img_train, X_emb_train, y_train, y_train_idx,
        X_img_val, X_emb_val, y_val
    )


# ============================================
# ğŸ”§ MAIN â€” ×¨×§ Build Cache
# ============================================

if __name__ == "__main__":
    build_cache()
