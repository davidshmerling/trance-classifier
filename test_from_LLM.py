import os
import json
import time
import random
import shutil
from pathlib import Path

import yt_dlp
import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
from mutagen.mp3 import MP3
from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix
import seaborn as sns
import openaito

# =========================
# CONFIG
# =========================

# × ×ª×™×‘×™×
MODEL_PATH = os.path.join("models", "latest.h5")
TMP_DIR = "tmp_llm_test"
RESULT_DIR = "result_test_random_llm_tracks"
JSON_OUTPUT = "results.json"

# ×”×’×“×¨×•×ª ××•×“×œ / ×“××˜×”
IMG_SIZE = (299, 299)
NUM_TESTS = 30        # ×›××” ×˜×¨×§×™× ×œ×‘×“×•×§ (××¤×©×¨ ×œ×©× ×•×ª ×œ-100)
VALID_GENRES = ["goa", "psy", "dark"]
CLASS_NAMES = ["Goa", "Psy", "Dark"]  # ×œ×¤×™ ××” ×©××™×× ×ª

# ××¤×ª×— ×œ-LLM
openai.api_key = os.getenv("OPENAI_API_KEY")

os.makedirs(TMP_DIR, exist_ok=True)


# =========================
# LLM: ×‘×§×©×ª ×˜×¨×§ ××”×–'×× ×¨
# =========================
def ask_llm_for_track(genre: str) -> dict:
    """
    ××‘×§×© ×××•×“×œ ×”×©×¤×” ×œ×”×¦×™×¢ ×˜×¨×§ ×¨× ×“×•××œ×™ ×‘×¡×’× ×•×Ÿ ××‘×•×§×© (goa/psy/dark).
    ××—×–×™×¨ dict ×¢×: artist, title, search_query, raw_answer.
    """
    if openai.api_key is None:
        raise RuntimeError("×œ× ×”×•×’×“×¨ OPENAI_API_KEY ×‘××©×ª× ×™ ×”×¡×‘×™×‘×”")

    # ××™×¤×•×™ ×›×“×™ ×©×”××•×“×œ ×™×‘×™×Ÿ ×˜×•×‘
    genre_prompt_name = {
        "goa": "Goa trance",
        "psy": "Psytrance",
        "dark": "Darkpsy"
    }[genre]

    system_msg = (
        "You are a music assistant specializing in psytrance and its subgenres. "
        "You MUST reply in strict JSON with the keys: artist, title, search_query. "
        "search_query should be a good YouTube search string like 'Astrix Deep Jungle Walk'. "
        "Do NOT include any extra text, only valid JSON."
    )
    user_msg = (
        f"Give me one random full-length track in the style of {genre_prompt_name}. "
        f"Prefer tracks that exist on YouTube as audio or music videos. "
        f"Return JSON only."
    )

    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",  # ××¤×©×¨ ×œ×©× ×•×ª ×œ×“×’× ××—×¨
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg},
        ],
        temperature=0.9,
    )
    content = resp["choices"][0]["message"]["content"].strip()

    try:
        data = json.loads(content)
    except json.JSONDecodeError:
        # × ×¤×™×œ×”: ××—×–×™×¨×™× ×”×›×œ ×‘×ª×•×š search_query ×›×“×™ ×©×œ× × ×™×¤×•×œ
        return {
            "artist": "",
            "title": "",
            "search_query": content,
            "raw_answer": content,
        }

    data["raw_answer"] = content
    # ×”×‘×˜×—×ª ×©×“×•×ª ×‘×¡×™×¡×™×™×
    for key in ["artist", "title", "search_query"]:
        data.setdefault(key, "")

    return data


# =========================
# ×—×™×¤×•×© ×•×”×•×¨×“×” ×‘×™×•×˜×™×•×‘ ×¢× yt-dlp
# =========================
def search_and_download_youtube(search_query: str, out_mp3_path: str):
    """
    ××—×¤×© ××ª ×”×˜×¨×§ ×‘×™×•×˜×™×•×‘ ×‘×¢×–×¨×ª yt-dlp (ytsearch1:query) ×•××•×¨×™×“ ×›-MP3.
    ××—×–×™×¨ (success: bool, video_url: str|None).
    """
    ydl_opts = {
        "format": "bestaudio/best",
        "outtmpl": out_mp3_path,
        "quiet": True,
        "no_warnings": True,
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "128",
        }],
    }

    query = f"ytsearch1:{search_query}"

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(query, download=True)
    except Exception as e:
        print(f"âš ï¸ yt-dlp failed for query '{search_query}': {e}")
        return False, None

    # info ×™×›×•×œ ×œ×”×™×•×ª ×¢× entries
    video_url = None
    if "entries" in info and info["entries"]:
        entry = info["entries"][0]
        video_id = entry.get("id")
        if video_id:
            video_url = f"https://www.youtube.com/watch?v={video_id}"

    return True, video_url


# =========================
# ×™×¦×™×¨×ª ×¡×¤×§×˜×•×’×¨××”
# =========================
def create_spectrogram(y, sr, out_path):
    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
    S_db = librosa.power_to_db(S, ref=np.max)

    plt.figure(figsize=(2.99, 2.99), dpi=100)
    plt.axis("off")
    librosa.display.specshow(S_db, sr=sr, cmap='viridis')
    plt.savefig(out_path, bbox_inches='tight', pad_inches=0)
    plt.close()


# =========================
# ×—×™×ª×•×š ×˜×¨×§ ×œ×“×§×•×ª ×•×™×¦×™×¨×ª ×ª××•× ×•×ª
# =========================
def process_track(mp3_path: str):
    """
    ××—×–×™×¨ {"parts": [paths]} ××• {"error": "..."}.
    """
    try:
        audio = MP3(mp3_path)
        length_sec = int(audio.info.length)
    except Exception:
        return {"error": "invalid_mp3"}

    # ×™×•×ª×¨ ×-15 ×“×§×•×ª â†’ ×œ× ××ª××™×
    if length_sec > 900:
        return {"error": "too_long"}

    num_parts = length_sec // 60
    if num_parts < 1:
        return {"error": "too_short"}

    try:
        y, sr = librosa.load(mp3_path, sr=22050, mono=True)
    except Exception:
        return {"error": "librosa_load_failed"}

    image_paths = []
    for part in range(num_parts):
        start = part * 60
        end = start + 60
        seg = y[start * sr:min(end * sr, len(y))]

        img_path = os.path.join(TMP_DIR, f"{Path(mp3_path).stem}_part_{part + 1}.png")
        create_spectrogram(seg, sr, img_path)
        image_paths.append(img_path)

    return {"parts": image_paths}


# =========================
# ×”×¨×¦×ª ×”××•×“×œ ×¢×œ ×›×œ ×”×ª××•× ×•×ª
# =========================
def run_model_on_images(model, image_paths, class_names):
    """
    ××—×–×™×¨ (part_results, avg_probs, final_label)
    """
    avg = {c: 0.0 for c in class_names}
    part_results = []

    for idx, img_path in enumerate(image_paths, start=1):
        img_arr = plt.imread(img_path).astype("float32") / 255.0
        img_arr = np.expand_dims(img_arr, axis=0)

        probs = model.predict(img_arr, verbose=0)[0]
        prob_dict = {class_names[i]: float(probs[i]) for i in range(len(class_names))}

        part_results.append({
            "part": idx,
            "probabilities": prob_dict,
            "image_path": img_path,
        })

        for c in class_names:
            avg[c] += prob_dict[c]

    for c in class_names:
        avg[c] /= len(image_paths)

    final = max(avg, key=avg.get)
    return part_results, avg, final


# =========================
# ×ª×™×§×™×™×ª ×ª×•×¦××•×ª
# =========================
def prepare_result_dir():
    if os.path.exists(RESULT_DIR):
        shutil.rmtree(RESULT_DIR)
    os.makedirs(RESULT_DIR, exist_ok=True)


# =========================
# Confusion Matrix + Accuracy per genre
# =========================
def save_confusion_matrix(true_labels, pred_labels):
    if not true_labels:
        return

    cm = confusion_matrix(true_labels, pred_labels, labels=VALID_GENRES)

    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d",
                xticklabels=VALID_GENRES,
                yticklabels=VALID_GENRES,
                cmap="Blues")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix - Random LLM YouTube Tracks")
    plt.tight_layout()
    plt.savefig(os.path.join(RESULT_DIR, "confusion_matrix.png"))
    plt.close()


def save_genre_accuracy_plot(true_labels, pred_labels):
    if not true_labels:
        return

    counts = {g: {"correct": 0, "total": 0} for g in VALID_GENRES}
    for t, p in zip(true_labels, pred_labels):
        counts[t]["total"] += 1
        if t == p:
            counts[t]["correct"] += 1

    genres = VALID_GENRES
    acc = []
    for g in genres:
        if counts[g]["total"] > 0:
            acc.append(counts[g]["correct"] / counts[g]["total"] * 100)
        else:
            acc.append(0.0)

    plt.figure(figsize=(6, 4))
    plt.bar(genres, acc)
    plt.ylabel("Accuracy %")
    plt.title("Accuracy Per Genre (LLM YouTube Test)")
    plt.ylim(0, 100)
    plt.grid(axis="y")
    plt.tight_layout()
    plt.savefig(os.path.join(RESULT_DIR, "genre_accuracy.png"))
    plt.close()


# =========================
# × ×™×§×•×™ TMP
# =========================
def cleanup_tmp():
    for f in os.listdir(TMP_DIR):
        full = os.path.join(TMP_DIR, f)
        if os.path.isfile(full):
            os.remove(full)


# =========================
# MAIN TEST
# =========================
def test_random_tracks_with_llm():
    prepare_result_dir()

    print("\nğŸš€ ××ª×—×™×œ ×‘×“×™×§×ª ×˜×¨×§×™× ×¨× ×“×•××œ×™×™× ××™×•×˜×™×•×‘ ×‘×¢×–×¨×ª LLM...\n")

    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"×œ× × ××¦× ××•×“×œ ×‘× ×ª×™×‘: {MODEL_PATH}")

    model = load_model(MODEL_PATH)

    results = []
    true_labels = []
    pred_labels = []

    start_time = time.time()

    for i in range(1, NUM_TESTS + 1):
        print(f"\n========== ×˜×¨×§ {i}/{NUM_TESTS} ==========")

        # 1. ×‘×•×—×¨×™× ×–'×× ×¨ ×××™×ª×™
        true_genre = random.choice(VALID_GENRES)

        # 2. ××‘×§×©×™× ××”-LLM ×˜×¨×§ ××”×–'×× ×¨ ×”×–×”
        try:
            llm_data = ask_llm_for_track(true_genre)
        except Exception as e:
            print(f"âš ï¸ LLM request failed: {e}")
            results.append({
                "index": i,
                "true_genre": true_genre,
                "error": "llm_failed",
                "exception": str(e),
            })
            continue

        search_query = llm_data.get("search_query", "").strip()
        if not search_query:
            print("âš ï¸ LLM did not return a valid search_query")
            results.append({
                "index": i,
                "true_genre": true_genre,
                "llm_data": llm_data,
                "error": "no_search_query",
            })
            continue

        print(f"ğŸ¯ ×–'×× ×¨ ××‘×•×§×©: {true_genre} | ×©××™×œ×ª×ª ×—×™×¤×•×©: {search_query}")

        # 3. ××—×¤×©×™× ×‘×™×•×˜×™×•×‘ ×•××•×¨×™×“×™×
        mp3_path = os.path.join(TMP_DIR, f"llm_test_{i}.mp3")
        success, video_url = search_and_download_youtube(search_query, mp3_path)

        if not success or not os.path.exists(mp3_path):
            print("âš ï¸ download/search failed")
            results.append({
                "index": i,
                "true_genre": true_genre,
                "llm_data": llm_data,
                "video_url": video_url,
                "error": "download_failed",
            })
            continue

        # 4. ×™×•×¦×¨×™× ×—×œ×§×™× ×•×ª××•× ×•×ª
        processed = process_track(mp3_path)
        if "error" in processed:
            print(f"âš ï¸ process_track error: {processed['error']}")
            results.append({
                "index": i,
                "true_genre": true_genre,
                "llm_data": llm_data,
                "video_url": video_url,
                "error": processed["error"],
            })
            # ××•×—×§×™× ××ª ×”-MP3 ×‘×›×œ ××§×¨×”
            if os.path.exists(mp3_path):
                os.remove(mp3_path)
            continue

        image_paths = processed["parts"]
        if not image_paths:
            print("âš ï¸ no image parts created")
            results.append({
                "index": i,
                "true_genre": true_genre,
                "llm_data": llm_data,
                "video_url": video_url,
                "error": "no_image_parts",
            })
            if os.path.exists(mp3_path):
                os.remove(mp3_path)
            continue

        # 5. ×”×¨×¦×ª ×”××•×“×œ
        t0 = time.time()
        part_results, avg_probs, final_label = run_model_on_images(model, image_paths, CLASS_NAMES)
        runtime = round(time.time() - t0, 2)

        # ××™×¤×•×™ ×œ×©××•×ª lowercase ×©×œ valid genres
        predicted_genre_lower = final_label.lower()
        is_correct = (predicted_genre_lower == true_genre.lower())

        print(f"âœ… ×ª×—×–×™×ª ×¡×•×¤×™×ª: {final_label} (truth: {true_genre}) | correct={is_correct}")

        results.append({
            "index": i,
            "true_genre": true_genre,
            "llm_data": llm_data,
            "video_url": video_url,
            "predicted_label": final_label,
            "predicted_genre_lower": predicted_genre_lower,
            "correct": is_correct,
            "average_probs": avg_probs,
            "parts": part_results,
            "runtime_sec": runtime,
        })

        true_labels.append(true_genre)
        if predicted_genre_lower in VALID_GENRES:
            pred_labels.append(predicted_genre_lower)
        else:
            pred_labels.append("unknown")

        # ××•×—×§×™× ××ª ×”-MP3
        if os.path.exists(mp3_path):
            os.remove(mp3_path)

        # ××•×—×§×™× ××ª ×”×ª××•× ×•×ª ×©×™×¦×¨× ×•
        for p in image_paths:
            if os.path.exists(p):
                os.remove(p)

    # =========================
    # ×©××™×¨×ª JSON + ×’×¨×¤×™×
    # =========================
    json_path = os.path.join(RESULT_DIR, JSON_OUTPUT)
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=4, ensure_ascii=False)

    save_confusion_matrix(true_labels, pred_labels)
    save_genre_accuracy_plot(true_labels, pred_labels)

    total_runtime = round(time.time() - start_time, 2)
    cleanup_tmp()

    print(f"\nâ± ×–××Ÿ ×¨×™×¦×” ×›×•×œ×œ: {total_runtime} ×©× ×™×•×ª")
    print(f"ğŸ“„ ×ª×•×¦××•×ª × ×©××¨×• ×‘- {json_path}")
    print(f"ğŸ“Š Confusion matrix + accuracy per genre × ×©××¨×• ×‘×ª×™×§×™×™×”: {RESULT_DIR}")
    print("âœ”ï¸ ×”×¡×ª×™×™×!")


if __name__ == "__main__":
    test_random_tracks_with_llm()
